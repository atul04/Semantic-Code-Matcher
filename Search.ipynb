{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Build Search Index.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should have completed steps 1-4 of this tutorial before beginning this exercise. The files required for this notebook are generated by those previous steps.\n",
    "\n",
    "Creating the search engine for this example is extremely CPU and memory intensive. We used an an AWS x1.32xlarge instance (128 cores) in order to achieve the maximum speed with building the search index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import nmslib\n",
    "from lang_model_utils import load_lm_vocab, Query2Emb\n",
    "from general_utils import create_nmslib_search_index\n",
    "\n",
    "input_path = Path('./data/processed_data/')\n",
    "code2emb_path = Path('./data/code2emb/')\n",
    "output_path = Path('./data/search')\n",
    "output_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will want to organize the data that we will want to display for the search results, which will be:\n",
    "\n",
    "    1. The original code\n",
    "    2. A link to the original code\n",
    "\n",
    "For convenience, we will collect this data into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-04-06 02:39:31--  https://storage.googleapis.com/kubeflow-examples/code_search/data/without_docstrings.lineage\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.167.176, 2404:6800:4009:810::2010\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.167.176|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 361370651 (345M) [application/octet-stream]\n",
      "Saving to: ‘./data/processed_data/without_docstrings.lineage.1’\n",
      "\n",
      "without_docstrings. 100%[===================>] 344.63M  9.83MB/s    in 38s     \n",
      "\n",
      "2020-04-06 02:40:10 (9.13 MB/s) - ‘./data/processed_data/without_docstrings.lineage.1’ saved [361370651/361370651]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget  https://storage.googleapis.com/kubeflow-examples/code_search/data/without_docstrings.lineage -P ./data/processed_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-04-06 02:40:14--  https://storage.googleapis.com/kubeflow-examples/code_search/data/without_docstrings_original_function.json.gz\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.167.176, 2404:6800:4009:810::2010\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.167.176|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 374037066 (357M) [application/json]\n",
      "Saving to: ‘./data/processed_data/without_docstrings_original_function.json.gz.1’\n",
      "\n",
      "without_docstrings_ 100%[===================>] 356.71M  10.2MB/s    in 41s     \n",
      "\n",
      "2020-04-06 02:40:57 (8.69 MB/s) - ‘./data/processed_data/without_docstrings_original_function.json.gz.1’ saved [374037066/374037066]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://storage.googleapis.com/kubeflow-examples/code_search/data/without_docstrings_original_function.json.gz -P ./data/processed_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://github.com/fnl/libfnl/blob/master/src/...</td>\n",
       "      <td>def __init__(self, *leafs, **edges):\\n    self...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://github.com/fnl/libfnl/blob/master/src/...</td>\n",
       "      <td>def __eq__(self, other):\\n    if isinstance(ot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://github.com/fnl/libfnl/blob/master/src/...</td>\n",
       "      <td>def __repr__(self):\\n    return 'Node&lt;leafs={}...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://github.com/fnl/libfnl/blob/master/src/...</td>\n",
       "      <td>@staticmethod\\ndef _isCapitalized(token):\\n   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://github.com/fnl/libfnl/blob/master/src/...</td>\n",
       "      <td>@staticmethod\\ndef _isCapitalizeD(last, token)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://github.com/fnl/libfnl/blob/master/src/...   \n",
       "1  https://github.com/fnl/libfnl/blob/master/src/...   \n",
       "2  https://github.com/fnl/libfnl/blob/master/src/...   \n",
       "3  https://github.com/fnl/libfnl/blob/master/src/...   \n",
       "4  https://github.com/fnl/libfnl/blob/master/src/...   \n",
       "\n",
       "                                                code  \n",
       "0  def __init__(self, *leafs, **edges):\\n    self...  \n",
       "1  def __eq__(self, other):\\n    if isinstance(ot...  \n",
       "2  def __repr__(self):\\n    return 'Node<leafs={}...  \n",
       "3  @staticmethod\\ndef _isCapitalized(token):\\n   ...  \n",
       "4  @staticmethod\\ndef _isCapitalizeD(last, token)...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read file of urls\n",
    "url_df = pd.read_csv(input_path/'without_docstrings.lineage',header=None, names=['url'])\n",
    "# url_df = url_df.iloc[1:]\n",
    "# read original code\n",
    "code_df = pd.read_json(input_path/'without_docstrings_original_function.json.gz')\n",
    "code_df.columns = ['code']\n",
    "# print(code_df.shape)\n",
    "# make sure these files have same number of rows\n",
    "assert code_df.shape[0] == url_df.shape[0]\n",
    "\n",
    "# collect these two together into a dataframe\n",
    "ref_df = pd.concat([url_df, code_df], axis = 1).reset_index(drop=True)\n",
    "ref_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4008718"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "For reference the above files are also available for download incase you skipped step 1:\n",
    "\n",
    "without_docstrings.lineage: https://storage.googleapis.com/kubeflow-examples/code_search/data/without_docstrings.lineage\n",
    "\n",
    "without_docstrings_original_function.json.gz: https://storage.googleapis.com/kubeflow-examples/code_search/data/without_docstrings_original_function.json.gz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Search Index For Vectorized Code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "First read in the vectorized code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodoc_vecs = np.load(code2emb_path/'nodoc_vecs.npy')\n",
    "# print(nodoc_vecs.shape)\n",
    "# print(ref_df.shape)\n",
    "# print(nodoc_vecs.head(3))\n",
    "# print(ref_df.head(3))\n",
    "assert nodoc_vecs.shape[0] == ref_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Now build the search index. Warning: this step takes ~ 18 minutes on an x1.32xlarge instance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11h 14min 40s, sys: 7min 9s, total: 11h 21min 49s\n",
      "Wall time: 28min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "search_index = create_nmslib_search_index(nodoc_vecs)\n",
    "search_index.saveIndex('./data/search/search_index.nmslib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cached version of this index can be downloaded here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create A Minimal Search Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "You can find the cached version of the required files on google cloud:\n",
    "\n",
    "lang_model_cpu_v2.torch: https://storage.googleapis.com/kubeflow-examples/code_search/data/lang_model/lang_model_cpu_v2.torch\n",
    "\n",
    "vocab_v2.cls: https://storage.googleapis.com/kubeflow-examples/code_search/data/lang_model/vocab_v2.cls\n",
    "\n",
    "search_index.nmslib: https://storage.googleapis.com/kubeflow-examples/code_search/data/search/search_index.nmslib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Loaded vocab of size 23,573\n",
      "WARNING:root:Processing 1 rows\n"
     ]
    }
   ],
   "source": [
    "lang_model = torch.load('./data/lang_model/lang_model_cpu_v2.torch', \n",
    "                        map_location=lambda storage, loc: storage)\n",
    "\n",
    "vocab = load_lm_vocab('./data/lang_model/vocab_v2.cls')\n",
    "q2emb = Query2Emb(lang_model = lang_model.cpu(),\n",
    "                  vocab = vocab)\n",
    "\n",
    "search_index = nmslib.init(method='hnsw', space='cosinesimil')\n",
    "search_index.loadIndex('./data/search/search_index.nmslib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Query2Emb is a helper class that will vectorize sentences using the language model trained in Part 3.\n",
    "\n",
    "In this case, we call the method emb_mean because we are taking the mean over the time steps of the hidden states in order to construct a sentence embedding for the query supplied by the user.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Processing 1 rows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 500)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = q2emb.emb_mean('Hello World!  This is a test.')\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an object to make the process of showing search results easier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below object organizes all the pieces together for searching the index and displaying the results with a method call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class search_engine:\n",
    "    \"\"\"Organizes all the necessary elements we need to make a search engine.\"\"\"\n",
    "    def __init__(self, \n",
    "                 nmslib_index, \n",
    "                 ref_df, \n",
    "                 query2emb_func):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ==========\n",
    "        nmslib_index : nmslib object\n",
    "            This is pre-computed search index.\n",
    "        ref_df : pandas.DataFrame\n",
    "            This dataframe contains meta-data for search results, \n",
    "            must contain the columns 'code' and 'url'.\n",
    "        query2emb_func : callable\n",
    "            This is a function that takes as input a string and returns a vector\n",
    "            that is in the same vector space as what is loaded into the search index.\n",
    "\n",
    "        \"\"\"\n",
    "        assert 'url' in ref_df.columns\n",
    "        assert 'code' in ref_df.columns\n",
    "        \n",
    "        self.search_index = nmslib_index\n",
    "        self.ref_df = ref_df\n",
    "        self.query2emb_func = query2emb_func\n",
    "    \n",
    "    def search(self, str_search, k=2):\n",
    "        \"\"\"\n",
    "        Prints the code that are the nearest neighbors (by cosine distance)\n",
    "        to the search query.\n",
    "        \n",
    "        Parameters\n",
    "        ==========\n",
    "        str_search : str\n",
    "            a search query.  Ex: \"read data into pandas dataframe\"\n",
    "        k : int\n",
    "            the number of nearest neighbors to return.  Defaults to 2.\n",
    "        \n",
    "        \"\"\"\n",
    "        query = self.query2emb_func(str_search)\n",
    "        idxs, dists = self.search_index.knnQuery(query, k=k)\n",
    "        \n",
    "        for idx, dist in zip(idxs, dists):\n",
    "            code = self.ref_df.iloc[idx].code\n",
    "            url = self.ref_df.iloc[idx].url\n",
    "            print(f'cosine dist:{dist:.4f}  url: {url}\\n---------------\\n')\n",
    "            print(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "se = search_engine(nmslib_index=search_index,\n",
    "                   ref_df=ref_df,\n",
    "                   query2emb_func=q2emb.emb_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Some Queries Against The Index!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have instantiated the search engine, we can use the search method to display the results.\n",
    "\n",
    "Warning: some of the displayed links may not work since this is historical data retrieved from a historical open dataset Google has hosted on BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Processing 1 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine dist:0.9101  url: https://github.com/imiolek-ireneusz/eduActiv8/blob/master/game_boards/game062.py#L207\n",
      "---------------\n",
      "\n",
      "def draw_splash(self, canvas, size, color, outline_color):\n",
      "    pygame.draw.polygon(canvas, color, self.scaled_lines, 0)\n",
      "    pygame.draw.aalines(canvas, outline_color, True, self.scaled_lines)\n",
      "\n",
      "cosine dist:0.9107  url: https://github.com/stleon/vk_friends/blob/master/graph.py#L25\n",
      "---------------\n",
      "\n",
      "def draw_graph(self):\n",
      "    plt.figure(figsize=(19, 19), dpi=450)\n",
      "    nx.draw(self.graph, node_size=100, cmap=True)\n",
      "    plt.savefig('%s graph.png' % datetime.now().strftime('%H:%M:%S %d-%m-%Y'))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "se.search('read data into pandas dataframe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Custom Ipython Magic Function To Create A Fake Search Box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You don't know how to build a website? No problem! You can still impress your friends by using a custom magic function to allow you to do a live demonstration in a Jupyter notebook. This is what I did when I first created this prototype!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magic import (register_line_magic, register_cell_magic,\n",
    "                                register_line_cell_magic)\n",
    "@register_cell_magic\n",
    "def search(line, cell):\n",
    "    return se.search(cell,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Live Semantic Search of Code (Searching Holdout Set Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Processing 1 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine dist:0.8901  url: https://github.com/kamwar/simLAB/blob/master/sim/sim_reader.py#L39\n",
      "---------------\n",
      "\n",
      "def close(self):\n",
      "    threadId = threading.current_thread().ident\n",
      "    if threadId in self.handlers.keys():\n",
      "        try:\n",
      "            self.handlers[threadId].close()\n",
      "        except:\n",
      "            pass\n",
      "        del self.handlers[threadId]\n",
      "    if self.server:\n",
      "        self.server.close()\n",
      "\n",
      "cosine dist:0.8906  url: https://github.com/Juniper/contrail-sandesh/blob/master/library/python/pysandesh/tcp_session.py#L45\n",
      "---------------\n",
      "\n",
      "def close(self):\n",
      "    if self._connected:\n",
      "        self._socket.close()\n",
      "        self._connected = False\n",
      "        self._handle_event(self.SESSION_CLOSE)\n",
      "\n",
      "cosine dist:0.8911  url: https://github.com/ruchee/vimrc/blob/master/vimfiles/bundle/vdebug/pythonx/vdebug/session.py#L79\n",
      "---------------\n",
      "\n",
      "def close(self):\n",
      "    self.stop_listening()\n",
      "    if self.is_connected():\n",
      "        self.__session.close_connection()\n",
      "    if self.is_open():\n",
      "        self.__ui.close()\n",
      "\n",
      "cosine dist:0.8912  url: https://github.com/cloudify-cosmo/cloudify-plugins-common/blob/master/cloudify/amqp_client.py#L103\n",
      "---------------\n",
      "\n",
      "def close(self):\n",
      "    if self._is_closed:\n",
      "        return\n",
      "    self._is_closed = True\n",
      "    thread = threading.current_thread()\n",
      "    if self.channel:\n",
      "        logger.debug('Closing amqp channel of thread {0}'.format(thread))\n",
      "        try:\n",
      "            self.channel.close()\n",
      "        except Exception as e:\n",
      "            logger.debug(\n",
      "                'Failed to close amqp channel of thread {0}, reported error: {1}'\n",
      "                .format(thread, repr(e)))\n",
      "    if self.connection:\n",
      "        logger.debug('Closing amqp connection of thread {0}'.format(thread))\n",
      "        try:\n",
      "            self.connection.close()\n",
      "        except Exception as e:\n",
      "            logger.debug(\n",
      "                'Failed to close amqp connection of thread {0}, reported error: {1}'\n",
      "                .format(thread, repr(e)))\n",
      "\n",
      "cosine dist:0.8915  url: https://github.com/quantmind/pulsar/blob/master/pulsar/apps/http/wsgi.py#L32\n",
      "---------------\n",
      "\n",
      "def close(self):\n",
      "    self._is_closing = True\n",
      "    self.connection.connection_lost(None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%search\n",
    "def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-34-d851ced96a63>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-34-d851ced96a63>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    search me\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "search me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
